{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6bf3e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T23:02:21.616952Z",
     "iopub.status.busy": "2025-12-13T23:02:21.616733Z",
     "iopub.status.idle": "2025-12-13T23:02:31.193942Z",
     "shell.execute_reply": "2025-12-13T23:02:31.193156Z"
    },
    "papermill": {
     "duration": 9.582651,
     "end_time": "2025-12-13T23:02:31.195332",
     "exception": false,
     "start_time": "2025-12-13T23:02:21.612681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26db4c42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T23:02:31.201757Z",
     "iopub.status.busy": "2025-12-13T23:02:31.201476Z",
     "iopub.status.idle": "2025-12-13T23:02:31.284410Z",
     "shell.execute_reply": "2025-12-13T23:02:31.283734Z"
    },
    "papermill": {
     "duration": 0.087308,
     "end_time": "2025-12-13T23:02:31.285537",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.198229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "# UPDATE THIS PATH based on your Kaggle Data tab\n",
    "DATA_PATH = \"/kaggle/input/amlfif/Dataset\" \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 25\n",
    "NUM_CLASSES = 200\n",
    "IMAGE_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2cd8e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T23:02:31.292113Z",
     "iopub.status.busy": "2025-12-13T23:02:31.291548Z",
     "iopub.status.idle": "2025-12-13T23:02:31.298462Z",
     "shell.execute_reply": "2025-12-13T23:02:31.297979Z"
    },
    "papermill": {
     "duration": 0.01123,
     "end_time": "2025-12-13T23:02:31.299515",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.288285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Adjust label to be 0-199 (PyTorch starts at 0)\n",
    "        if 'label' in self.data.columns:\n",
    "            self.data['label'] = self.data['label'] - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the row by position\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # --- SMART DETECTION START ---\n",
    "        # We use .iloc[] to avoid the FutureWarning\n",
    "        val0 = row.iloc[0]\n",
    "        val1 = row.iloc[1]\n",
    "        \n",
    "        # Check which one is the image path (string ending in .jpg)\n",
    "        if isinstance(val0, str) and (val0.endswith('.jpg') or '/' in val0):\n",
    "            img_path = val0\n",
    "            label_or_id = val1\n",
    "        else:\n",
    "            img_path = val1\n",
    "            label_or_id = val0\n",
    "        # --- SMART DETECTION END ---\n",
    "        \n",
    "        # Handle leading slashes\n",
    "        if str(img_path).startswith(\"/\"):\n",
    "            img_path = img_path[1:]\n",
    "            \n",
    "        full_path = os.path.join(self.root_dir, img_path)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(full_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            image = Image.new('RGB', (224, 224))\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Return proper pair\n",
    "        if 'label' in self.data.columns:\n",
    "            # Training: Return (Image, Label)\n",
    "            return image, torch.tensor(label_or_id, dtype=torch.long)\n",
    "        else:\n",
    "            # Testing: Return (Image, ID)\n",
    "            return image, label_or_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eec59bfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T23:02:31.305616Z",
     "iopub.status.busy": "2025-12-13T23:02:31.305123Z",
     "iopub.status.idle": "2025-12-13T23:02:31.309694Z",
     "shell.execute_reply": "2025-12-13T23:02:31.309195Z"
    },
    "papermill": {
     "duration": 0.008719,
     "end_time": "2025-12-13T23:02:31.310722",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.302003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. TRANSFORMS (Data Augmentation)\n",
    "# ==========================================\n",
    "# Innovation: Adding augmentation helps the model generalize better\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Flip left/right\n",
    "    transforms.RandomRotation(degrees=15),   # Rotate slightly\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1), # vary lighting\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490dfd28",
   "metadata": {
    "papermill": {
     "duration": 0.002458,
     "end_time": "2025-12-13T23:02:31.315694",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.313236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841e477",
   "metadata": {
    "papermill": {
     "duration": 0.002422,
     "end_time": "2025-12-13T23:02:31.320556",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.318134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22cfbaf5",
   "metadata": {
    "papermill": {
     "duration": 0.00243,
     "end_time": "2025-12-13T23:02:31.325406",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.322976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Improvised Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3603db95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T23:02:31.331422Z",
     "iopub.status.busy": "2025-12-13T23:02:31.331021Z",
     "iopub.status.idle": "2025-12-13T23:02:31.336394Z",
     "shell.execute_reply": "2025-12-13T23:02:31.335900Z"
    },
    "papermill": {
     "duration": 0.009468,
     "end_time": "2025-12-13T23:02:31.337328",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.327860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# IMPROVED MODEL: Mini-ResNet\n",
    "# ==========================================\n",
    "\n",
    "# 1. The Building Block (The Innovation)\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # First convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Second convolution\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # The \"Skip Connection\" logic\n",
    "        # If the input size changes (due to stride), we need to resize the shortcut too\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x # Save the original input (the \"jump\")\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        out += self.shortcut(identity) # ADD the original input back here\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132369da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T23:02:31.343287Z",
     "iopub.status.busy": "2025-12-13T23:02:31.343001Z",
     "iopub.status.idle": "2025-12-13T23:02:31.350652Z",
     "shell.execute_reply": "2025-12-13T23:02:31.350139Z"
    },
    "papermill": {
     "duration": 0.01174,
     "end_time": "2025-12-13T23:02:31.351575",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.339835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# IMPROVED MODEL: ResNet with Dropout\n",
    "# ==========================================\n",
    "class ResNetFromScratch(nn.Module):\n",
    "    def __init__(self, num_classes=200):\n",
    "        super(ResNetFromScratch, self).__init__()\n",
    "        \n",
    "        # Initial processing (Entry point)\n",
    "        self.in_channels = 64\n",
    "        # Standard ResNet Start\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Stack the Residual Blocks\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "        \n",
    "        # Classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # --- INNOVATION: Dropout ---\n",
    "        # Dropping 50% of neurons prevents overfitting on small datasets\n",
    "        self.dropout = nn.Dropout(p=0.5) \n",
    "        \n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        # Initialize weights (Helps training start better)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, out_channels, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Apply Dropout before the final classification\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ffed4",
   "metadata": {
    "papermill": {
     "duration": 0.002414,
     "end_time": "2025-12-13T23:02:31.356344",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.353930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42fb6746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T23:02:31.362120Z",
     "iopub.status.busy": "2025-12-13T23:02:31.361950Z",
     "iopub.status.idle": "2025-12-13T23:02:31.390953Z",
     "shell.execute_reply": "2025-12-13T23:02:31.390491Z"
    },
    "papermill": {
     "duration": 0.033158,
     "end_time": "2025-12-13T23:02:31.391954",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.358796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. SETUP LOADERS & MODEL\n",
    "# ==========================================\n",
    "# Load Data\n",
    "full_dataset = BirdDataset(\n",
    "    csv_file=f'{DATA_PATH}/train_images.csv', \n",
    "    root_dir=f'{DATA_PATH}',\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "# Split 80/20\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# IMPORTANT: Validation set should NOT use augmentation (just resize)\n",
    "val_dataset.dataset.transform = val_transforms \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3364805d",
   "metadata": {
    "papermill": {
     "duration": 0.002384,
     "end_time": "2025-12-13T23:02:31.396773",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.394389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b01e5d",
   "metadata": {
    "papermill": {
     "duration": 0.002297,
     "end_time": "2025-12-13T23:02:31.401471",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.399174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ac19b45",
   "metadata": {
    "papermill": {
     "duration": 0.002286,
     "end_time": "2025-12-13T23:02:31.406088",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.403802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Restnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad66b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.002352,
     "end_time": "2025-12-13T23:02:31.410793",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.408441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6db84c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T23:02:31.416333Z",
     "iopub.status.busy": "2025-12-13T23:02:31.416135Z",
     "iopub.status.idle": "2025-12-13T23:08:39.060043Z",
     "shell.execute_reply": "2025-12-13T23:08:39.059233Z"
    },
    "papermill": {
     "duration": 367.651221,
     "end_time": "2025-12-13T23:08:39.064337",
     "exception": false,
     "start_time": "2025-12-13T23:02:31.413116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ResNet with Dropout & OneCycleLR...\n",
      "Starting training on cuda for 25 epochs...\n",
      "Epoch 1/25 | Train Loss: 5.4217 | Val Loss: 5.1655 | Val Acc: 0.0165 | LR: 0.000245\n",
      "Epoch 2/25 | Train Loss: 5.1391 | Val Loss: 6.6682 | Val Acc: 0.0127 | LR: 0.000599\n",
      "Epoch 3/25 | Train Loss: 5.0296 | Val Loss: 6.0228 | Val Acc: 0.0127 | LR: 0.001120\n",
      "Epoch 4/25 | Train Loss: 4.9378 | Val Loss: 5.2204 | Val Acc: 0.0254 | LR: 0.001717\n",
      "Epoch 5/25 | Train Loss: 4.7875 | Val Loss: 5.0910 | Val Acc: 0.0382 | LR: 0.002287\n",
      "Epoch 6/25 | Train Loss: 4.7294 | Val Loss: 5.0016 | Val Acc: 0.0344 | LR: 0.002731\n",
      "Epoch 7/25 | Train Loss: 4.5585 | Val Loss: 4.8162 | Val Acc: 0.0433 | LR: 0.002971\n",
      "Epoch 8/25 | Train Loss: 4.4347 | Val Loss: 4.6442 | Val Acc: 0.0344 | LR: 0.002993\n",
      "Epoch 9/25 | Train Loss: 4.2639 | Val Loss: 5.6397 | Val Acc: 0.0369 | LR: 0.002945\n",
      "Epoch 10/25 | Train Loss: 4.2445 | Val Loss: 5.0098 | Val Acc: 0.0433 | LR: 0.002849\n",
      "Epoch 11/25 | Train Loss: 4.1102 | Val Loss: 4.7392 | Val Acc: 0.0712 | LR: 0.002710\n",
      "Epoch 12/25 | Train Loss: 3.9255 | Val Loss: 4.6175 | Val Acc: 0.0623 | LR: 0.002533\n",
      "Epoch 13/25 | Train Loss: 3.7659 | Val Loss: 4.2162 | Val Acc: 0.0967 | LR: 0.002322\n",
      "Epoch 14/25 | Train Loss: 3.5267 | Val Loss: 4.2397 | Val Acc: 0.0891 | LR: 0.002085\n",
      "Epoch 15/25 | Train Loss: 3.4872 | Val Loss: 4.3221 | Val Acc: 0.0878 | LR: 0.001829\n",
      "Epoch 16/25 | Train Loss: 3.2527 | Val Loss: 4.0190 | Val Acc: 0.1247 | LR: 0.001562\n",
      "Epoch 17/25 | Train Loss: 3.0341 | Val Loss: 4.0736 | Val Acc: 0.1221 | LR: 0.001293\n",
      "Epoch 18/25 | Train Loss: 2.8771 | Val Loss: 4.0723 | Val Acc: 0.1399 | LR: 0.001031\n",
      "Epoch 19/25 | Train Loss: 2.6448 | Val Loss: 4.0004 | Val Acc: 0.1438 | LR: 0.000784\n",
      "Epoch 20/25 | Train Loss: 2.4464 | Val Loss: 3.9376 | Val Acc: 0.1425 | LR: 0.000561\n",
      "Epoch 21/25 | Train Loss: 2.2004 | Val Loss: 3.9645 | Val Acc: 0.1578 | LR: 0.000367\n",
      "Epoch 22/25 | Train Loss: 2.0342 | Val Loss: 3.8867 | Val Acc: 0.1654 | LR: 0.000210\n",
      "Epoch 23/25 | Train Loss: 1.8566 | Val Loss: 3.8438 | Val Acc: 0.1578 | LR: 0.000094\n",
      "Epoch 24/25 | Train Loss: 1.7565 | Val Loss: 3.8252 | Val Acc: 0.1641 | LR: 0.000023\n",
      "Epoch 25/25 | Train Loss: 1.6792 | Val Loss: 3.8393 | Val Acc: 0.1679 | LR: 0.000000\n",
      "\n",
      "Training complete in 6m 7s\n",
      "Best Validation Accuracy: 0.1679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. SUPER-CONVERGENCE TRAINING LOOP\n",
    "# ==========================================\n",
    "import time\n",
    "\n",
    "# 1. SETUP\n",
    "\n",
    "print(\"Initializing ResNet with Dropout & OneCycleLR...\")\n",
    "model = ResNetFromScratch(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# OPTIMIZER: AdamW (Better weight decay handling)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# SCHEDULER: OneCycleLR\n",
    "# This ramps the LR up to 'max_lr' then down to 0. \n",
    "# It is extremely effective for training from scratch.\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, \n",
    "    max_lr=0.003,              # Peak learning rate\n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=len(train_loader)\n",
    ")\n",
    "\n",
    "# 2. TRAINING ENGINE\n",
    "# -----------------------------\n",
    "best_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Starting training on {DEVICE} for {EPOCHS} epochs...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # --- TRAIN PHASE ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # STEP SCHEDULER (OneCycleLR updates every BATCH, not every EPOCH)\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # --- VALIDATION PHASE ---\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels) # Calc val loss too\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    val_acc = correct / total\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    \n",
    "    # Get current LR for printout\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {epoch_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | LR: {current_lr:.6f}\")\n",
    "    \n",
    "    # --- SAVE BEST MODEL ---\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(model.state_dict(), 'best_custom_model.pth')\n",
    "\n",
    "# End of training\n",
    "time_elapsed = time.time() - start_time\n",
    "print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "print(f'Best Validation Accuracy: {best_acc:.4f}')\n",
    "\n",
    "# Load best weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "886cd554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T23:08:39.073019Z",
     "iopub.status.busy": "2025-12-13T23:08:39.072812Z",
     "iopub.status.idle": "2025-12-13T23:09:27.212796Z",
     "shell.execute_reply": "2025-12-13T23:09:27.211300Z"
    },
    "papermill": {
     "duration": 48.148378,
     "end_time": "2025-12-13T23:09:27.216884",
     "exception": false,
     "start_time": "2025-12-13T23:08:39.068506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Saved submission_scratch.csv!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 7. GENERATE SUBMISSION\n",
    "# ==========================================\n",
    "# Load Best Model\n",
    "model.load_state_dict(torch.load('best_custom_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_dataset = BirdDataset(\n",
    "    csv_file=f'{DATA_PATH}/test_images_path.csv',\n",
    "    root_dir=f'{DATA_PATH}',\n",
    "    transform=val_transforms # No augmentation for testing\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "all_ids = []\n",
    "\n",
    "print(\"Generating predictions...\")\n",
    "with torch.no_grad():\n",
    "    for inputs, ids in test_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Convert back to 1-200 range\n",
    "        predicted = predicted.cpu().numpy() + 1 \n",
    "        \n",
    "        all_preds.extend(predicted)\n",
    "        all_ids.extend(ids.numpy())\n",
    "\n",
    "# Save CSV\n",
    "submission = pd.DataFrame({'id': all_ids, 'label': all_preds})\n",
    "submission.to_csv('submission_scratch4.csv', index=False)\n",
    "print(\"Saved submission_scratch.csv!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13909210,
     "sourceId": 116520,
     "sourceType": "competition"
    },
    {
     "datasetId": 9010436,
     "sourceId": 14139279,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 430.641553,
   "end_time": "2025-12-13T23:09:28.740745",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-13T23:02:18.099192",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
