{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ad640f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:29:07.625422Z",
     "iopub.status.busy": "2025-12-14T10:29:07.624965Z",
     "iopub.status.idle": "2025-12-14T10:29:17.343720Z",
     "shell.execute_reply": "2025-12-14T10:29:17.342880Z"
    },
    "papermill": {
     "duration": 9.72444,
     "end_time": "2025-12-14T10:29:17.345129",
     "exception": false,
     "start_time": "2025-12-14T10:29:07.620689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f44241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:29:17.352348Z",
     "iopub.status.busy": "2025-12-14T10:29:17.351806Z",
     "iopub.status.idle": "2025-12-14T10:29:17.433416Z",
     "shell.execute_reply": "2025-12-14T10:29:17.432793Z"
    },
    "papermill": {
     "duration": 0.086327,
     "end_time": "2025-12-14T10:29:17.434539",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.348212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "# UPDATE THIS PATH based on your Kaggle Data tab\n",
    "DATA_PATH = \"/kaggle/input/amlfif/Dataset\" \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 200\n",
    "IMAGE_SIZE = 448\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449555b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:29:17.441317Z",
     "iopub.status.busy": "2025-12-14T10:29:17.440952Z",
     "iopub.status.idle": "2025-12-14T10:29:17.447748Z",
     "shell.execute_reply": "2025-12-14T10:29:17.447053Z"
    },
    "papermill": {
     "duration": 0.011341,
     "end_time": "2025-12-14T10:29:17.448824",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.437483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Adjust label to be 0-199 (PyTorch starts at 0)\n",
    "        if 'label' in self.data.columns:\n",
    "            self.data['label'] = self.data['label'] - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the row by position\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # --- SMART DETECTION START ---\n",
    "        # We use .iloc[] to avoid the FutureWarning\n",
    "        val0 = row.iloc[0]\n",
    "        val1 = row.iloc[1]\n",
    "        \n",
    "        # Check which one is the image path (string ending in .jpg)\n",
    "        if isinstance(val0, str) and (val0.endswith('.jpg') or '/' in val0):\n",
    "            img_path = val0\n",
    "            label_or_id = val1\n",
    "        else:\n",
    "            img_path = val1\n",
    "            label_or_id = val0\n",
    "            \n",
    "        # --- SMART DETECTION END ---\n",
    "        \n",
    "        # Handle leading slashes\n",
    "        if str(img_path).startswith(\"/\"):\n",
    "            img_path = img_path[1:]\n",
    "            \n",
    "        full_path = os.path.join(self.root_dir, img_path)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(full_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            image = Image.new('RGB', (224, 224))\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Return proper pair\n",
    "        if 'label' in self.data.columns:\n",
    "            # Training: Return (Image, Label)\n",
    "            return image, torch.tensor(label_or_id, dtype=torch.long)\n",
    "        else:\n",
    "            # Testing: Return (Image, ID)\n",
    "            return image, label_or_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76acdbb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:29:17.455069Z",
     "iopub.status.busy": "2025-12-14T10:29:17.454593Z",
     "iopub.status.idle": "2025-12-14T10:29:17.459876Z",
     "shell.execute_reply": "2025-12-14T10:29:17.459023Z"
    },
    "papermill": {
     "duration": 0.009619,
     "end_time": "2025-12-14T10:29:17.461007",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.451388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. TRANSFORMS (Data Augmentation)\n",
    "# ==========================================\n",
    "# Innovation: Adding augmentation helps the model generalize better\n",
    "# train_transforms = transforms.Compose([\n",
    "#     transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),  # Flip left/right\n",
    "#     transforms.RandomRotation(degrees=15),   # Rotate slightly\n",
    "#     transforms.ColorJitter(brightness=0.1, contrast=0.1), # vary lighting\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    # This is the single most important augmentation for classification\n",
    "    transforms.RandomResizedCrop((IMAGE_SIZE, IMAGE_SIZE), scale=(0.6, 1.0)), \n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93bbde55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:29:17.467055Z",
     "iopub.status.busy": "2025-12-14T10:29:17.466854Z",
     "iopub.status.idle": "2025-12-14T10:29:17.471370Z",
     "shell.execute_reply": "2025-12-14T10:29:17.470706Z"
    },
    "papermill": {
     "duration": 0.00877,
     "end_time": "2025-12-14T10:29:17.472459",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.463689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    \n",
    "    # Sample lambda from Beta distribution (controls mix ratio)\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    # Get batch size and generate a random permutaion of indices for shuffling\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(DEVICE)\n",
    "\n",
    "    # Linearly combine original inputs with shuffled inputs and create paired labels for mixup loss computation\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c6cc5",
   "metadata": {
    "papermill": {
     "duration": 0.002534,
     "end_time": "2025-12-14T10:29:17.477598",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.475064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196cde8",
   "metadata": {
    "papermill": {
     "duration": 0.002498,
     "end_time": "2025-12-14T10:29:17.482683",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.480185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d97257c7",
   "metadata": {
    "papermill": {
     "duration": 0.002453,
     "end_time": "2025-12-14T10:29:17.487598",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.485145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Improvised Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a15a45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:29:17.493720Z",
     "iopub.status.busy": "2025-12-14T10:29:17.493315Z",
     "iopub.status.idle": "2025-12-14T10:29:17.499237Z",
     "shell.execute_reply": "2025-12-14T10:29:17.498562Z"
    },
    "papermill": {
     "duration": 0.01014,
     "end_time": "2025-12-14T10:29:17.500309",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.490169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# IMPROVED MODEL: Mini-ResNet\n",
    "# ==========================================\n",
    "\n",
    "# 1. The Building Block (The Innovation)\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # First convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Second convolution\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # The \"Skip Connection\" logic\n",
    "        # If the input size changes (due to stride), we need to resize the shortcut too\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x # Save the original input (the \"jump\")\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        out += self.shortcut(identity) # ADD the original input back here\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c595f5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:29:17.506486Z",
     "iopub.status.busy": "2025-12-14T10:29:17.506005Z",
     "iopub.status.idle": "2025-12-14T10:29:17.513959Z",
     "shell.execute_reply": "2025-12-14T10:29:17.513443Z"
    },
    "papermill": {
     "duration": 0.012155,
     "end_time": "2025-12-14T10:29:17.515018",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.502863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# IMPROVED MODEL: ResNet with Dropout\n",
    "# ==========================================\n",
    "class ResNetFromScratch(nn.Module):\n",
    "    def __init__(self, num_classes=200):\n",
    "        super(ResNetFromScratch, self).__init__()\n",
    "        \n",
    "        # Initial processing (Entry point)\n",
    "        self.in_channels = 64\n",
    "        # Standard ResNet Start\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Stack the Residual Blocks\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "        \n",
    "        # Classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # --- INNOVATION: Dropout ---\n",
    "        # Dropping 50% of neurons prevents overfitting on small datasets\n",
    "        self.dropout = nn.Dropout(p=0.5) \n",
    "        \n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        # Initialize weights (Helps training start better)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, out_channels, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Apply Dropout before the final classification\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d44612e",
   "metadata": {
    "papermill": {
     "duration": 0.002538,
     "end_time": "2025-12-14T10:29:17.520182",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.517644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b99158a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:29:17.526421Z",
     "iopub.status.busy": "2025-12-14T10:29:17.525937Z",
     "iopub.status.idle": "2025-12-14T10:29:17.562024Z",
     "shell.execute_reply": "2025-12-14T10:29:17.561550Z"
    },
    "papermill": {
     "duration": 0.040346,
     "end_time": "2025-12-14T10:29:17.563052",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.522706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. SETUP LOADERS & MODEL\n",
    "# ==========================================\n",
    "# Load Data\n",
    "full_dataset = BirdDataset(\n",
    "    csv_file=f'{DATA_PATH}/train_images.csv', \n",
    "    root_dir=f'{DATA_PATH}',\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "# Split 80/20\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# IMPORTANT: Validation set should NOT use augmentation (just resize)\n",
    "val_dataset.dataset.transform = val_transforms \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0d2152",
   "metadata": {
    "papermill": {
     "duration": 0.002479,
     "end_time": "2025-12-14T10:29:17.568146",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.565667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678d8b5",
   "metadata": {
    "papermill": {
     "duration": 0.002455,
     "end_time": "2025-12-14T10:29:17.573145",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.570690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e9a77ec",
   "metadata": {
    "papermill": {
     "duration": 0.002504,
     "end_time": "2025-12-14T10:29:17.578195",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.575691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Restnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1ede4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.002502,
     "end_time": "2025-12-14T10:29:17.583253",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.580751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bfc6d31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T10:29:17.589221Z",
     "iopub.status.busy": "2025-12-14T10:29:17.589049Z",
     "iopub.status.idle": "2025-12-14T11:53:19.302704Z",
     "shell.execute_reply": "2025-12-14T11:53:19.301827Z"
    },
    "papermill": {
     "duration": 5041.722985,
     "end_time": "2025-12-14T11:53:19.308741",
     "exception": false,
     "start_time": "2025-12-14T10:29:17.585756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ResNet with Dropout & OneCycleLR...\n",
      "Starting training on cuda for 100 epochs...\n",
      "Epoch 1/100 | Train Loss: 5.3949 | Val Loss: 5.2858 | Val Acc: 0.0204 | LR: 0.000128\n",
      "Epoch 2/100 | Train Loss: 5.1995 | Val Loss: 5.4374 | Val Acc: 0.0318 | LR: 0.000152\n",
      "Epoch 3/100 | Train Loss: 5.1089 | Val Loss: 5.0783 | Val Acc: 0.0318 | LR: 0.000191\n",
      "Epoch 4/100 | Train Loss: 5.0595 | Val Loss: 5.0751 | Val Acc: 0.0280 | LR: 0.000245\n",
      "Epoch 5/100 | Train Loss: 5.0095 | Val Loss: 5.2222 | Val Acc: 0.0305 | LR: 0.000313\n",
      "Epoch 6/100 | Train Loss: 4.9978 | Val Loss: 5.0741 | Val Acc: 0.0407 | LR: 0.000395\n",
      "Epoch 7/100 | Train Loss: 4.9734 | Val Loss: 5.0113 | Val Acc: 0.0458 | LR: 0.000490\n",
      "Epoch 8/100 | Train Loss: 4.9178 | Val Loss: 5.0175 | Val Acc: 0.0356 | LR: 0.000597\n",
      "Epoch 9/100 | Train Loss: 4.9356 | Val Loss: 4.9912 | Val Acc: 0.0318 | LR: 0.000714\n",
      "Epoch 10/100 | Train Loss: 4.8907 | Val Loss: 5.0333 | Val Acc: 0.0394 | LR: 0.000841\n",
      "Epoch 11/100 | Train Loss: 4.8806 | Val Loss: 5.0262 | Val Acc: 0.0471 | LR: 0.000975\n",
      "Epoch 12/100 | Train Loss: 4.8409 | Val Loss: 4.9150 | Val Acc: 0.0382 | LR: 0.001116\n",
      "Epoch 13/100 | Train Loss: 4.8043 | Val Loss: 5.2617 | Val Acc: 0.0394 | LR: 0.001262\n",
      "Epoch 14/100 | Train Loss: 4.7286 | Val Loss: 4.8857 | Val Acc: 0.0573 | LR: 0.001411\n",
      "Epoch 15/100 | Train Loss: 4.7517 | Val Loss: 5.1979 | Val Acc: 0.0598 | LR: 0.001562\n",
      "Epoch 16/100 | Train Loss: 4.6352 | Val Loss: 4.7498 | Val Acc: 0.0687 | LR: 0.001712\n",
      "Epoch 17/100 | Train Loss: 4.7046 | Val Loss: 4.7693 | Val Acc: 0.0649 | LR: 0.001861\n",
      "Epoch 18/100 | Train Loss: 4.6665 | Val Loss: 4.7079 | Val Acc: 0.0738 | LR: 0.002007\n",
      "Epoch 19/100 | Train Loss: 4.5737 | Val Loss: 4.7808 | Val Acc: 0.0560 | LR: 0.002147\n",
      "Epoch 20/100 | Train Loss: 4.5535 | Val Loss: 4.8140 | Val Acc: 0.0700 | LR: 0.002282\n",
      "Epoch 21/100 | Train Loss: 4.5817 | Val Loss: 4.8444 | Val Acc: 0.0802 | LR: 0.002408\n",
      "Epoch 22/100 | Train Loss: 4.4768 | Val Loss: 5.0004 | Val Acc: 0.0763 | LR: 0.002525\n",
      "Epoch 23/100 | Train Loss: 4.4553 | Val Loss: 4.5507 | Val Acc: 0.0738 | LR: 0.002632\n",
      "Epoch 24/100 | Train Loss: 4.4251 | Val Loss: 4.6668 | Val Acc: 0.0814 | LR: 0.002726\n",
      "Epoch 25/100 | Train Loss: 4.3394 | Val Loss: 4.4492 | Val Acc: 0.1043 | LR: 0.002808\n",
      "Epoch 26/100 | Train Loss: 4.3244 | Val Loss: 6.2764 | Val Acc: 0.0573 | LR: 0.002877\n",
      "Epoch 27/100 | Train Loss: 4.3338 | Val Loss: 4.5529 | Val Acc: 0.0954 | LR: 0.002930\n",
      "Epoch 28/100 | Train Loss: 4.3018 | Val Loss: 4.4952 | Val Acc: 0.1043 | LR: 0.002969\n",
      "Epoch 29/100 | Train Loss: 4.2420 | Val Loss: 4.6903 | Val Acc: 0.0878 | LR: 0.002992\n",
      "Epoch 30/100 | Train Loss: 4.1991 | Val Loss: 4.3098 | Val Acc: 0.1285 | LR: 0.003000\n",
      "Epoch 31/100 | Train Loss: 4.1304 | Val Loss: 5.4833 | Val Acc: 0.0611 | LR: 0.002998\n",
      "Epoch 32/100 | Train Loss: 4.1412 | Val Loss: 4.3110 | Val Acc: 0.1361 | LR: 0.002994\n",
      "Epoch 33/100 | Train Loss: 4.0335 | Val Loss: 4.4565 | Val Acc: 0.1132 | LR: 0.002986\n",
      "Epoch 34/100 | Train Loss: 3.8961 | Val Loss: 4.1983 | Val Acc: 0.1489 | LR: 0.002976\n",
      "Epoch 35/100 | Train Loss: 4.0675 | Val Loss: 4.1694 | Val Acc: 0.1298 | LR: 0.002962\n",
      "Epoch 36/100 | Train Loss: 3.7577 | Val Loss: 4.8007 | Val Acc: 0.0954 | LR: 0.002946\n",
      "Epoch 37/100 | Train Loss: 3.9821 | Val Loss: 4.2629 | Val Acc: 0.1476 | LR: 0.002926\n",
      "Epoch 38/100 | Train Loss: 3.8511 | Val Loss: 4.1993 | Val Acc: 0.1616 | LR: 0.002904\n",
      "Epoch 39/100 | Train Loss: 3.8448 | Val Loss: 4.4041 | Val Acc: 0.1285 | LR: 0.002879\n",
      "Epoch 40/100 | Train Loss: 3.6451 | Val Loss: 4.0307 | Val Acc: 0.1908 | LR: 0.002851\n",
      "Epoch 41/100 | Train Loss: 3.6083 | Val Loss: 4.3302 | Val Acc: 0.1425 | LR: 0.002820\n",
      "Epoch 42/100 | Train Loss: 3.6635 | Val Loss: 4.2539 | Val Acc: 0.1539 | LR: 0.002787\n",
      "Epoch 43/100 | Train Loss: 3.4232 | Val Loss: 3.9087 | Val Acc: 0.2214 | LR: 0.002751\n",
      "Epoch 44/100 | Train Loss: 3.4408 | Val Loss: 4.0687 | Val Acc: 0.1896 | LR: 0.002713\n",
      "Epoch 45/100 | Train Loss: 3.4146 | Val Loss: 4.0763 | Val Acc: 0.1832 | LR: 0.002672\n",
      "Epoch 46/100 | Train Loss: 3.4672 | Val Loss: 3.9746 | Val Acc: 0.2061 | LR: 0.002629\n",
      "Epoch 47/100 | Train Loss: 3.3541 | Val Loss: 4.0452 | Val Acc: 0.1985 | LR: 0.002583\n",
      "Epoch 48/100 | Train Loss: 3.3954 | Val Loss: 3.9054 | Val Acc: 0.2405 | LR: 0.002536\n",
      "Epoch 49/100 | Train Loss: 2.9740 | Val Loss: 3.8585 | Val Acc: 0.2328 | LR: 0.002486\n",
      "Epoch 50/100 | Train Loss: 3.1387 | Val Loss: 3.8378 | Val Acc: 0.2316 | LR: 0.002434\n",
      "Epoch 51/100 | Train Loss: 2.8661 | Val Loss: 3.8149 | Val Acc: 0.2468 | LR: 0.002381\n",
      "Epoch 52/100 | Train Loss: 2.9063 | Val Loss: 4.1701 | Val Acc: 0.1781 | LR: 0.002325\n",
      "Epoch 53/100 | Train Loss: 2.8096 | Val Loss: 3.9602 | Val Acc: 0.2226 | LR: 0.002268\n",
      "Epoch 54/100 | Train Loss: 2.6167 | Val Loss: 3.8634 | Val Acc: 0.2392 | LR: 0.002210\n",
      "Epoch 55/100 | Train Loss: 2.4618 | Val Loss: 3.9218 | Val Acc: 0.2532 | LR: 0.002150\n",
      "Epoch 56/100 | Train Loss: 2.5071 | Val Loss: 3.8358 | Val Acc: 0.2430 | LR: 0.002088\n",
      "Epoch 57/100 | Train Loss: 2.5317 | Val Loss: 3.8241 | Val Acc: 0.2494 | LR: 0.002026\n",
      "Epoch 58/100 | Train Loss: 2.7263 | Val Loss: 3.8569 | Val Acc: 0.2405 | LR: 0.001962\n",
      "Epoch 59/100 | Train Loss: 2.5921 | Val Loss: 3.9313 | Val Acc: 0.2417 | LR: 0.001898\n",
      "Epoch 60/100 | Train Loss: 2.4976 | Val Loss: 3.8530 | Val Acc: 0.2443 | LR: 0.001832\n",
      "Epoch 61/100 | Train Loss: 2.5614 | Val Loss: 3.7606 | Val Acc: 0.2494 | LR: 0.001767\n",
      "Epoch 62/100 | Train Loss: 2.3939 | Val Loss: 3.8157 | Val Acc: 0.2608 | LR: 0.001700\n",
      "Epoch 63/100 | Train Loss: 2.4404 | Val Loss: 3.8721 | Val Acc: 0.2443 | LR: 0.001633\n",
      "Epoch 64/100 | Train Loss: 2.2701 | Val Loss: 3.8917 | Val Acc: 0.2265 | LR: 0.001566\n",
      "Epoch 65/100 | Train Loss: 2.3717 | Val Loss: 3.8529 | Val Acc: 0.2443 | LR: 0.001499\n",
      "Epoch 66/100 | Train Loss: 2.2632 | Val Loss: 3.7657 | Val Acc: 0.2659 | LR: 0.001431\n",
      "Epoch 67/100 | Train Loss: 2.1818 | Val Loss: 3.7499 | Val Acc: 0.2723 | LR: 0.001364\n",
      "Epoch 68/100 | Train Loss: 2.0955 | Val Loss: 3.8323 | Val Acc: 0.2494 | LR: 0.001297\n",
      "Epoch 69/100 | Train Loss: 2.0961 | Val Loss: 3.8020 | Val Acc: 0.2748 | LR: 0.001231\n",
      "Epoch 70/100 | Train Loss: 2.1971 | Val Loss: 3.7981 | Val Acc: 0.2494 | LR: 0.001165\n",
      "Epoch 71/100 | Train Loss: 2.2175 | Val Loss: 3.7428 | Val Acc: 0.2748 | LR: 0.001100\n",
      "Epoch 72/100 | Train Loss: 1.8249 | Val Loss: 3.6963 | Val Acc: 0.2901 | LR: 0.001035\n",
      "Epoch 73/100 | Train Loss: 1.9956 | Val Loss: 3.7577 | Val Acc: 0.2723 | LR: 0.000972\n",
      "Epoch 74/100 | Train Loss: 2.3047 | Val Loss: 3.7779 | Val Acc: 0.2672 | LR: 0.000909\n",
      "Epoch 75/100 | Train Loss: 2.1359 | Val Loss: 3.7129 | Val Acc: 0.2990 | LR: 0.000848\n",
      "Epoch 76/100 | Train Loss: 2.1462 | Val Loss: 3.7928 | Val Acc: 0.2812 | LR: 0.000788\n",
      "Epoch 77/100 | Train Loss: 2.2634 | Val Loss: 3.7854 | Val Acc: 0.2774 | LR: 0.000730\n",
      "Epoch 78/100 | Train Loss: 2.0701 | Val Loss: 3.7090 | Val Acc: 0.2964 | LR: 0.000673\n",
      "Epoch 79/100 | Train Loss: 2.1279 | Val Loss: 3.7420 | Val Acc: 0.2812 | LR: 0.000617\n",
      "Epoch 80/100 | Train Loss: 2.0471 | Val Loss: 3.6982 | Val Acc: 0.3028 | LR: 0.000564\n",
      "Epoch 81/100 | Train Loss: 1.8409 | Val Loss: 3.7096 | Val Acc: 0.2913 | LR: 0.000512\n",
      "Epoch 82/100 | Train Loss: 2.2234 | Val Loss: 3.7477 | Val Acc: 0.2863 | LR: 0.000462\n",
      "Epoch 83/100 | Train Loss: 1.9125 | Val Loss: 3.7123 | Val Acc: 0.2901 | LR: 0.000415\n",
      "Epoch 84/100 | Train Loss: 2.0360 | Val Loss: 3.7188 | Val Acc: 0.2875 | LR: 0.000370\n",
      "Epoch 85/100 | Train Loss: 2.1751 | Val Loss: 3.7569 | Val Acc: 0.2926 | LR: 0.000326\n",
      "Epoch 86/100 | Train Loss: 1.9671 | Val Loss: 3.7401 | Val Acc: 0.2926 | LR: 0.000286\n",
      "Epoch 87/100 | Train Loss: 1.9755 | Val Loss: 3.7816 | Val Acc: 0.3066 | LR: 0.000247\n",
      "Epoch 88/100 | Train Loss: 2.0569 | Val Loss: 3.7182 | Val Acc: 0.3053 | LR: 0.000212\n",
      "Epoch 89/100 | Train Loss: 2.0382 | Val Loss: 3.7438 | Val Acc: 0.2952 | LR: 0.000178\n",
      "Epoch 90/100 | Train Loss: 2.0907 | Val Loss: 3.7380 | Val Acc: 0.3003 | LR: 0.000148\n",
      "Epoch 91/100 | Train Loss: 1.8927 | Val Loss: 3.7243 | Val Acc: 0.3015 | LR: 0.000120\n",
      "Epoch 92/100 | Train Loss: 2.0068 | Val Loss: 3.7340 | Val Acc: 0.3066 | LR: 0.000095\n",
      "Epoch 93/100 | Train Loss: 1.8790 | Val Loss: 3.7289 | Val Acc: 0.2964 | LR: 0.000073\n",
      "Epoch 94/100 | Train Loss: 2.0360 | Val Loss: 3.7350 | Val Acc: 0.2977 | LR: 0.000054\n",
      "Epoch 95/100 | Train Loss: 2.1227 | Val Loss: 3.7381 | Val Acc: 0.3028 | LR: 0.000037\n",
      "Epoch 96/100 | Train Loss: 2.0028 | Val Loss: 3.7429 | Val Acc: 0.2888 | LR: 0.000024\n",
      "Epoch 97/100 | Train Loss: 2.3027 | Val Loss: 3.7469 | Val Acc: 0.3003 | LR: 0.000013\n",
      "Epoch 98/100 | Train Loss: 1.8825 | Val Loss: 3.7307 | Val Acc: 0.3003 | LR: 0.000006\n",
      "Epoch 99/100 | Train Loss: 1.8783 | Val Loss: 3.7421 | Val Acc: 0.2952 | LR: 0.000001\n",
      "Epoch 100/100 | Train Loss: 1.8126 | Val Loss: 3.7226 | Val Acc: 0.3053 | LR: 0.000000\n",
      "\n",
      "Training complete in 84m 1s\n",
      "Best Validation Accuracy: 0.3066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. SUPER-CONVERGENCE TRAINING LOOP\n",
    "# ==========================================\n",
    "import time\n",
    "\n",
    "# 1. SETUP\n",
    "\n",
    "print(\"Initializing ResNet with Dropout & OneCycleLR...\")\n",
    "model = ResNetFromScratch(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# OPTIMIZER: AdamW (Better weight decay handling)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# SCHEDULER: OneCycleLR\n",
    "# This ramps the LR up to 'max_lr' then down to 0. \n",
    "# It is extremely effective for training from scratch.\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, \n",
    "    max_lr=0.003,              # Peak learning rate\n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=len(train_loader)\n",
    ")\n",
    "\n",
    "# 2. TRAINING ENGINE\n",
    "# -----------------------------\n",
    "best_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Starting training on {DEVICE} for {EPOCHS} epochs...\")\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "    \n",
    "#     # --- TRAIN PHASE ---\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "    \n",
    "#     for inputs, labels in train_loader:\n",
    "#         inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         # Forward\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         # Backward\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         # STEP SCHEDULER (OneCycleLR updates every BATCH, not every EPOCH)\n",
    "#         scheduler.step()\n",
    "        \n",
    "#         running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "#     epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "# ... (Setup code remains the same) ...\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # --- TRAIN PHASE ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # --- MIXUP LOGIC START ---\n",
    "        # 1. Mix the inputs\n",
    "        inputs, targets_a, targets_b, lam = mixup_data(inputs, labels, alpha=0.4)\n",
    "        \n",
    "        # 2. Forward pass (on mixed images)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # 3. Calculate MixUp loss\n",
    "        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "        # --- MIXUP LOGIC END ---\n",
    "        \n",
    "        # DELETE THESE LINES FROM YOUR CODE:\n",
    "        # outputs = model(inputs)          <-- DELETE\n",
    "        # loss = criterion(outputs, labels)<-- DELETE (This was overwriting the mixup loss!)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # STEP SCHEDULER\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # ... (Validation phase remains the same) ...\n",
    "    \n",
    "    # --- VALIDATION PHASE ---\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    # Disable gradient computation for validation (saves memory and computation)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            # Forward pass and compute validation loss\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels) # Calc val loss too\n",
    "            \n",
    "            # Get predicted class indices\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Accumulate total validation loss and count total samples\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    # Compute average validation accuracy and validation loss\n",
    "    val_acc = correct / total\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    \n",
    "    # Get current LR for printout\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {epoch_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | LR: {current_lr:.6f}\")\n",
    "    \n",
    "    # --- SAVE BEST MODEL ---\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(model.state_dict(), 'best_custom_model.pth')\n",
    "\n",
    "# End of training\n",
    "time_elapsed = time.time() - start_time\n",
    "print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "print(f'Best Validation Accuracy: {best_acc:.4f}')\n",
    "\n",
    "# Load best weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c809152",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T11:53:19.322731Z",
     "iopub.status.busy": "2025-12-14T11:53:19.322480Z",
     "iopub.status.idle": "2025-12-14T11:54:42.945218Z",
     "shell.execute_reply": "2025-12-14T11:54:42.944416Z"
    },
    "papermill": {
     "duration": 83.636986,
     "end_time": "2025-12-14T11:54:42.952164",
     "exception": false,
     "start_time": "2025-12-14T11:53:19.315178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Saved submission_scratch.csv!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 7. GENERATE SUBMISSION\n",
    "# ==========================================\n",
    "# Load Best Model\n",
    "model.load_state_dict(torch.load('best_custom_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_dataset = BirdDataset(\n",
    "    csv_file=f'{DATA_PATH}/test_images_path.csv',\n",
    "    root_dir=f'{DATA_PATH}',\n",
    "    transform=val_transforms # No augmentation for testing\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "all_ids = []\n",
    "\n",
    "print(\"Generating predictions...\")\n",
    "with torch.no_grad():\n",
    "    for inputs, ids in test_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Convert back to 1-200 range\n",
    "        predicted = predicted.cpu().numpy() + 1 \n",
    "        \n",
    "        all_preds.extend(predicted)\n",
    "        all_ids.extend(ids.numpy())\n",
    "\n",
    "# Save CSV\n",
    "submission = pd.DataFrame({'id': all_ids, 'label': all_preds})\n",
    "submission.to_csv('submission_scratch6.csv', index=False)\n",
    "print(\"Saved submission_scratch.csv!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13909210,
     "sourceId": 116520,
     "sourceType": "competition"
    },
    {
     "datasetId": 9010436,
     "sourceId": 14139279,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5140.482821,
   "end_time": "2025-12-14T11:54:44.578959",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-14T10:29:04.096138",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
