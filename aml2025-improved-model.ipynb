{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70f51f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:32:16.972859Z",
     "iopub.status.busy": "2025-12-14T08:32:16.972606Z",
     "iopub.status.idle": "2025-12-14T08:32:26.262155Z",
     "shell.execute_reply": "2025-12-14T08:32:26.261375Z"
    },
    "papermill": {
     "duration": 9.295151,
     "end_time": "2025-12-14T08:32:26.263552",
     "exception": false,
     "start_time": "2025-12-14T08:32:16.968401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6683a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:32:26.270113Z",
     "iopub.status.busy": "2025-12-14T08:32:26.269791Z",
     "iopub.status.idle": "2025-12-14T08:32:26.350437Z",
     "shell.execute_reply": "2025-12-14T08:32:26.349746Z"
    },
    "papermill": {
     "duration": 0.085305,
     "end_time": "2025-12-14T08:32:26.351692",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.266387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "# UPDATE THIS PATH based on your Kaggle Data tab\n",
    "DATA_PATH = \"/kaggle/input/amlfif/Dataset\" \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 200\n",
    "IMAGE_SIZE = 448\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d78b01d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:32:26.358025Z",
     "iopub.status.busy": "2025-12-14T08:32:26.357774Z",
     "iopub.status.idle": "2025-12-14T08:32:26.364622Z",
     "shell.execute_reply": "2025-12-14T08:32:26.363927Z"
    },
    "papermill": {
     "duration": 0.011259,
     "end_time": "2025-12-14T08:32:26.365741",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.354482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Adjust label to be 0-199 (PyTorch starts at 0)\n",
    "        if 'label' in self.data.columns:\n",
    "            self.data['label'] = self.data['label'] - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the row by position\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # --- SMART DETECTION START ---\n",
    "        # We use .iloc[] to avoid the FutureWarning\n",
    "        val0 = row.iloc[0]\n",
    "        val1 = row.iloc[1]\n",
    "        \n",
    "        # Check which one is the image path (string ending in .jpg)\n",
    "        if isinstance(val0, str) and (val0.endswith('.jpg') or '/' in val0):\n",
    "            img_path = val0\n",
    "            label_or_id = val1\n",
    "        else:\n",
    "            img_path = val1\n",
    "            label_or_id = val0\n",
    "        # --- SMART DETECTION END ---\n",
    "        \n",
    "        # Handle leading slashes\n",
    "        if str(img_path).startswith(\"/\"):\n",
    "            img_path = img_path[1:]\n",
    "            \n",
    "        full_path = os.path.join(self.root_dir, img_path)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(full_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            image = Image.new('RGB', (224, 224))\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Return proper pair\n",
    "        if 'label' in self.data.columns:\n",
    "            # Training: Return (Image, Label)\n",
    "            return image, torch.tensor(label_or_id, dtype=torch.long)\n",
    "        else:\n",
    "            # Testing: Return (Image, ID)\n",
    "            return image, label_or_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2700ebce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:32:26.371599Z",
     "iopub.status.busy": "2025-12-14T08:32:26.371402Z",
     "iopub.status.idle": "2025-12-14T08:32:26.376254Z",
     "shell.execute_reply": "2025-12-14T08:32:26.375520Z"
    },
    "papermill": {
     "duration": 0.009041,
     "end_time": "2025-12-14T08:32:26.377354",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.368313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. TRANSFORMS (Data Augmentation)\n",
    "# ==========================================\n",
    "# Innovation: Adding augmentation helps the model generalize better\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Flip left/right\n",
    "    transforms.RandomRotation(degrees=15),   # Rotate slightly\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1), # vary lighting\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dd8329",
   "metadata": {
    "papermill": {
     "duration": 0.002383,
     "end_time": "2025-12-14T08:32:26.382299",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.379916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e304fe57",
   "metadata": {
    "papermill": {
     "duration": 0.002374,
     "end_time": "2025-12-14T08:32:26.387087",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.384713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5171f12a",
   "metadata": {
    "papermill": {
     "duration": 0.002295,
     "end_time": "2025-12-14T08:32:26.391797",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.389502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Improvised Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f3159e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:32:26.397450Z",
     "iopub.status.busy": "2025-12-14T08:32:26.397248Z",
     "iopub.status.idle": "2025-12-14T08:32:26.403091Z",
     "shell.execute_reply": "2025-12-14T08:32:26.402489Z"
    },
    "papermill": {
     "duration": 0.009929,
     "end_time": "2025-12-14T08:32:26.404088",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.394159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# IMPROVED MODEL: Mini-ResNet\n",
    "# ==========================================\n",
    "\n",
    "# 1. The Building Block (The Innovation)\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # First convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Second convolution\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # The \"Skip Connection\" logic\n",
    "        # If the input size changes (due to stride), we need to resize the shortcut too\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x # Save the original input (the \"jump\")\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        out += self.shortcut(identity) # ADD the original input back here\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2a2124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:32:26.410109Z",
     "iopub.status.busy": "2025-12-14T08:32:26.409891Z",
     "iopub.status.idle": "2025-12-14T08:32:26.418036Z",
     "shell.execute_reply": "2025-12-14T08:32:26.417512Z"
    },
    "papermill": {
     "duration": 0.012449,
     "end_time": "2025-12-14T08:32:26.419056",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.406607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# IMPROVED MODEL: ResNet with Dropout\n",
    "# ==========================================\n",
    "class ResNetFromScratch(nn.Module):\n",
    "    def __init__(self, num_classes=200):\n",
    "        super(ResNetFromScratch, self).__init__()\n",
    "        \n",
    "        # Initial processing (Entry point)\n",
    "        self.in_channels = 64\n",
    "        # Standard ResNet Start\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Stack the Residual Blocks\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "        \n",
    "        # Classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # --- INNOVATION: Dropout ---\n",
    "        # Dropping 50% of neurons prevents overfitting on small datasets\n",
    "        self.dropout = nn.Dropout(p=0.5) \n",
    "        \n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        # Initialize weights (Helps training start better)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, out_channels, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Apply Dropout before the final classification\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbec8be",
   "metadata": {
    "papermill": {
     "duration": 0.002406,
     "end_time": "2025-12-14T08:32:26.423855",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.421449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53c3983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:32:26.429427Z",
     "iopub.status.busy": "2025-12-14T08:32:26.429233Z",
     "iopub.status.idle": "2025-12-14T08:32:26.461094Z",
     "shell.execute_reply": "2025-12-14T08:32:26.460404Z"
    },
    "papermill": {
     "duration": 0.035861,
     "end_time": "2025-12-14T08:32:26.462165",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.426304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. SETUP LOADERS & MODEL\n",
    "# ==========================================\n",
    "# Load Data\n",
    "full_dataset = BirdDataset(\n",
    "    csv_file=f'{DATA_PATH}/train_images.csv', \n",
    "    root_dir=f'{DATA_PATH}',\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "# Split 80/20\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# IMPORTANT: Validation set should NOT use augmentation (just resize)\n",
    "val_dataset.dataset.transform = val_transforms \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a3b1fd",
   "metadata": {
    "papermill": {
     "duration": 0.002384,
     "end_time": "2025-12-14T08:32:26.467087",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.464703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4041da",
   "metadata": {
    "papermill": {
     "duration": 0.002348,
     "end_time": "2025-12-14T08:32:26.471863",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.469515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "417220ab",
   "metadata": {
    "papermill": {
     "duration": 0.002315,
     "end_time": "2025-12-14T08:32:26.476664",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.474349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Restnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2bb476",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.002349,
     "end_time": "2025-12-14T08:32:26.481405",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.479056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0e76904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:32:26.487196Z",
     "iopub.status.busy": "2025-12-14T08:32:26.486975Z",
     "iopub.status.idle": "2025-12-14T09:45:22.062023Z",
     "shell.execute_reply": "2025-12-14T09:45:22.061198Z"
    },
    "papermill": {
     "duration": 4375.585064,
     "end_time": "2025-12-14T09:45:22.068860",
     "exception": false,
     "start_time": "2025-12-14T08:32:26.483796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ResNet with Dropout & OneCycleLR...\n",
      "Starting training on cuda for 100 epochs...\n",
      "Epoch 1/100 | Train Loss: 5.4081 | Val Loss: 5.1934 | Val Acc: 0.0216 | LR: 0.000128\n",
      "Epoch 2/100 | Train Loss: 5.1062 | Val Loss: 5.1179 | Val Acc: 0.0242 | LR: 0.000152\n",
      "Epoch 3/100 | Train Loss: 5.0073 | Val Loss: 5.0449 | Val Acc: 0.0242 | LR: 0.000191\n",
      "Epoch 4/100 | Train Loss: 4.9097 | Val Loss: 5.2082 | Val Acc: 0.0356 | LR: 0.000245\n",
      "Epoch 5/100 | Train Loss: 4.8281 | Val Loss: 5.0208 | Val Acc: 0.0344 | LR: 0.000313\n",
      "Epoch 6/100 | Train Loss: 4.7823 | Val Loss: 4.9835 | Val Acc: 0.0471 | LR: 0.000395\n",
      "Epoch 7/100 | Train Loss: 4.7333 | Val Loss: 4.9522 | Val Acc: 0.0496 | LR: 0.000490\n",
      "Epoch 8/100 | Train Loss: 4.6622 | Val Loss: 5.0760 | Val Acc: 0.0369 | LR: 0.000597\n",
      "Epoch 9/100 | Train Loss: 4.5847 | Val Loss: 5.3362 | Val Acc: 0.0369 | LR: 0.000714\n",
      "Epoch 10/100 | Train Loss: 4.5530 | Val Loss: 5.1418 | Val Acc: 0.0369 | LR: 0.000841\n",
      "Epoch 11/100 | Train Loss: 4.4957 | Val Loss: 4.9498 | Val Acc: 0.0496 | LR: 0.000975\n",
      "Epoch 12/100 | Train Loss: 4.4584 | Val Loss: 5.0406 | Val Acc: 0.0356 | LR: 0.001116\n",
      "Epoch 13/100 | Train Loss: 4.3761 | Val Loss: 5.0757 | Val Acc: 0.0344 | LR: 0.001262\n",
      "Epoch 14/100 | Train Loss: 4.2682 | Val Loss: 4.8384 | Val Acc: 0.0700 | LR: 0.001411\n",
      "Epoch 15/100 | Train Loss: 4.1969 | Val Loss: 5.3611 | Val Acc: 0.0458 | LR: 0.001562\n",
      "Epoch 16/100 | Train Loss: 4.1811 | Val Loss: 5.1216 | Val Acc: 0.0344 | LR: 0.001712\n",
      "Epoch 17/100 | Train Loss: 4.2129 | Val Loss: 5.5033 | Val Acc: 0.0573 | LR: 0.001861\n",
      "Epoch 18/100 | Train Loss: 4.0372 | Val Loss: 4.5495 | Val Acc: 0.0738 | LR: 0.002007\n",
      "Epoch 19/100 | Train Loss: 3.9746 | Val Loss: 4.7129 | Val Acc: 0.0522 | LR: 0.002147\n",
      "Epoch 20/100 | Train Loss: 3.8535 | Val Loss: 4.9379 | Val Acc: 0.0649 | LR: 0.002282\n",
      "Epoch 21/100 | Train Loss: 3.8623 | Val Loss: 5.1000 | Val Acc: 0.0712 | LR: 0.002408\n",
      "Epoch 22/100 | Train Loss: 3.7411 | Val Loss: 4.8539 | Val Acc: 0.0751 | LR: 0.002525\n",
      "Epoch 23/100 | Train Loss: 3.7137 | Val Loss: 5.0414 | Val Acc: 0.0700 | LR: 0.002632\n",
      "Epoch 24/100 | Train Loss: 3.5769 | Val Loss: 5.0437 | Val Acc: 0.0700 | LR: 0.002726\n",
      "Epoch 25/100 | Train Loss: 3.5765 | Val Loss: 4.1471 | Val Acc: 0.1145 | LR: 0.002808\n",
      "Epoch 26/100 | Train Loss: 3.3748 | Val Loss: 5.9695 | Val Acc: 0.0814 | LR: 0.002877\n",
      "Epoch 27/100 | Train Loss: 3.3720 | Val Loss: 4.4441 | Val Acc: 0.0814 | LR: 0.002930\n",
      "Epoch 28/100 | Train Loss: 3.2601 | Val Loss: 6.2710 | Val Acc: 0.0509 | LR: 0.002969\n",
      "Epoch 29/100 | Train Loss: 3.2362 | Val Loss: 4.2677 | Val Acc: 0.1145 | LR: 0.002992\n",
      "Epoch 30/100 | Train Loss: 3.0691 | Val Loss: 4.1914 | Val Acc: 0.1438 | LR: 0.003000\n",
      "Epoch 31/100 | Train Loss: 2.9129 | Val Loss: 3.9896 | Val Acc: 0.1260 | LR: 0.002998\n",
      "Epoch 32/100 | Train Loss: 2.8037 | Val Loss: 4.6881 | Val Acc: 0.1336 | LR: 0.002994\n",
      "Epoch 33/100 | Train Loss: 2.6996 | Val Loss: 4.1644 | Val Acc: 0.1628 | LR: 0.002986\n",
      "Epoch 34/100 | Train Loss: 2.7736 | Val Loss: 3.9721 | Val Acc: 0.1323 | LR: 0.002976\n",
      "Epoch 35/100 | Train Loss: 2.4822 | Val Loss: 8.5688 | Val Acc: 0.0509 | LR: 0.002962\n",
      "Epoch 36/100 | Train Loss: 2.6246 | Val Loss: 4.4582 | Val Acc: 0.1425 | LR: 0.002946\n",
      "Epoch 37/100 | Train Loss: 2.3941 | Val Loss: 3.8792 | Val Acc: 0.1514 | LR: 0.002926\n",
      "Epoch 38/100 | Train Loss: 2.1920 | Val Loss: 4.5528 | Val Acc: 0.1412 | LR: 0.002904\n",
      "Epoch 39/100 | Train Loss: 2.1705 | Val Loss: 3.8586 | Val Acc: 0.1730 | LR: 0.002879\n",
      "Epoch 40/100 | Train Loss: 2.0288 | Val Loss: 4.2152 | Val Acc: 0.1768 | LR: 0.002851\n",
      "Epoch 41/100 | Train Loss: 1.8287 | Val Loss: 4.3771 | Val Acc: 0.1565 | LR: 0.002820\n",
      "Epoch 42/100 | Train Loss: 1.7384 | Val Loss: 4.0733 | Val Acc: 0.1705 | LR: 0.002787\n",
      "Epoch 43/100 | Train Loss: 1.8541 | Val Loss: 4.3970 | Val Acc: 0.1616 | LR: 0.002751\n",
      "Epoch 44/100 | Train Loss: 1.5620 | Val Loss: 4.6875 | Val Acc: 0.1743 | LR: 0.002713\n",
      "Epoch 45/100 | Train Loss: 1.4882 | Val Loss: 4.0701 | Val Acc: 0.2010 | LR: 0.002672\n",
      "Epoch 46/100 | Train Loss: 1.4021 | Val Loss: 4.2182 | Val Acc: 0.1959 | LR: 0.002629\n",
      "Epoch 47/100 | Train Loss: 1.1683 | Val Loss: 4.0349 | Val Acc: 0.1985 | LR: 0.002583\n",
      "Epoch 48/100 | Train Loss: 1.0496 | Val Loss: 4.6912 | Val Acc: 0.1985 | LR: 0.002536\n",
      "Epoch 49/100 | Train Loss: 1.1676 | Val Loss: 3.9636 | Val Acc: 0.2316 | LR: 0.002486\n",
      "Epoch 50/100 | Train Loss: 0.9707 | Val Loss: 4.5817 | Val Acc: 0.2036 | LR: 0.002434\n",
      "Epoch 51/100 | Train Loss: 1.0972 | Val Loss: 3.8265 | Val Acc: 0.2455 | LR: 0.002381\n",
      "Epoch 52/100 | Train Loss: 0.6992 | Val Loss: 4.6413 | Val Acc: 0.2163 | LR: 0.002325\n",
      "Epoch 53/100 | Train Loss: 0.7829 | Val Loss: 4.1855 | Val Acc: 0.2265 | LR: 0.002268\n",
      "Epoch 54/100 | Train Loss: 0.6605 | Val Loss: 4.7104 | Val Acc: 0.1997 | LR: 0.002210\n",
      "Epoch 55/100 | Train Loss: 0.7570 | Val Loss: 4.0794 | Val Acc: 0.2226 | LR: 0.002150\n",
      "Epoch 56/100 | Train Loss: 0.4845 | Val Loss: 4.9083 | Val Acc: 0.2087 | LR: 0.002088\n",
      "Epoch 57/100 | Train Loss: 0.7306 | Val Loss: 4.3990 | Val Acc: 0.2277 | LR: 0.002026\n",
      "Epoch 58/100 | Train Loss: 0.5392 | Val Loss: 4.1382 | Val Acc: 0.2468 | LR: 0.001962\n",
      "Epoch 59/100 | Train Loss: 0.2623 | Val Loss: 4.3102 | Val Acc: 0.2621 | LR: 0.001898\n",
      "Epoch 60/100 | Train Loss: 0.3316 | Val Loss: 4.4527 | Val Acc: 0.2405 | LR: 0.001832\n",
      "Epoch 61/100 | Train Loss: 0.4029 | Val Loss: 4.1204 | Val Acc: 0.2417 | LR: 0.001767\n",
      "Epoch 62/100 | Train Loss: 0.2457 | Val Loss: 4.4976 | Val Acc: 0.2201 | LR: 0.001700\n",
      "Epoch 63/100 | Train Loss: 0.3003 | Val Loss: 4.1020 | Val Acc: 0.2608 | LR: 0.001633\n",
      "Epoch 64/100 | Train Loss: 0.2105 | Val Loss: 4.2814 | Val Acc: 0.2570 | LR: 0.001566\n",
      "Epoch 65/100 | Train Loss: 0.2638 | Val Loss: 4.4297 | Val Acc: 0.2112 | LR: 0.001499\n",
      "Epoch 66/100 | Train Loss: 0.3437 | Val Loss: 4.4888 | Val Acc: 0.2290 | LR: 0.001431\n",
      "Epoch 67/100 | Train Loss: 0.2186 | Val Loss: 4.2079 | Val Acc: 0.2494 | LR: 0.001364\n",
      "Epoch 68/100 | Train Loss: 0.1581 | Val Loss: 4.1780 | Val Acc: 0.2621 | LR: 0.001297\n",
      "Epoch 69/100 | Train Loss: 0.1948 | Val Loss: 4.2169 | Val Acc: 0.2570 | LR: 0.001231\n",
      "Epoch 70/100 | Train Loss: 0.1998 | Val Loss: 4.2087 | Val Acc: 0.2697 | LR: 0.001165\n",
      "Epoch 71/100 | Train Loss: 0.2101 | Val Loss: 4.1008 | Val Acc: 0.2672 | LR: 0.001100\n",
      "Epoch 72/100 | Train Loss: 0.1586 | Val Loss: 4.2942 | Val Acc: 0.2506 | LR: 0.001035\n",
      "Epoch 73/100 | Train Loss: 0.1253 | Val Loss: 4.2624 | Val Acc: 0.2812 | LR: 0.000972\n",
      "Epoch 74/100 | Train Loss: 0.1193 | Val Loss: 4.1975 | Val Acc: 0.2710 | LR: 0.000909\n",
      "Epoch 75/100 | Train Loss: 0.1111 | Val Loss: 4.3030 | Val Acc: 0.2723 | LR: 0.000848\n",
      "Epoch 76/100 | Train Loss: 0.1202 | Val Loss: 4.2601 | Val Acc: 0.2595 | LR: 0.000788\n",
      "Epoch 77/100 | Train Loss: 0.1174 | Val Loss: 4.0743 | Val Acc: 0.2824 | LR: 0.000730\n",
      "Epoch 78/100 | Train Loss: 0.0801 | Val Loss: 4.2257 | Val Acc: 0.2583 | LR: 0.000673\n",
      "Epoch 79/100 | Train Loss: 0.0752 | Val Loss: 4.2553 | Val Acc: 0.2697 | LR: 0.000617\n",
      "Epoch 80/100 | Train Loss: 0.0791 | Val Loss: 4.0678 | Val Acc: 0.2672 | LR: 0.000564\n",
      "Epoch 81/100 | Train Loss: 0.0578 | Val Loss: 4.2625 | Val Acc: 0.2723 | LR: 0.000512\n",
      "Epoch 82/100 | Train Loss: 0.0426 | Val Loss: 4.2090 | Val Acc: 0.2672 | LR: 0.000462\n",
      "Epoch 83/100 | Train Loss: 0.0346 | Val Loss: 4.1768 | Val Acc: 0.2735 | LR: 0.000415\n",
      "Epoch 84/100 | Train Loss: 0.0329 | Val Loss: 4.2905 | Val Acc: 0.2646 | LR: 0.000370\n",
      "Epoch 85/100 | Train Loss: 0.0390 | Val Loss: 4.2955 | Val Acc: 0.2812 | LR: 0.000326\n",
      "Epoch 86/100 | Train Loss: 0.0523 | Val Loss: 4.2863 | Val Acc: 0.2659 | LR: 0.000286\n",
      "Epoch 87/100 | Train Loss: 0.0401 | Val Loss: 4.2019 | Val Acc: 0.2659 | LR: 0.000247\n",
      "Epoch 88/100 | Train Loss: 0.0377 | Val Loss: 4.2809 | Val Acc: 0.2646 | LR: 0.000212\n",
      "Epoch 89/100 | Train Loss: 0.0387 | Val Loss: 4.2538 | Val Acc: 0.2684 | LR: 0.000178\n",
      "Epoch 90/100 | Train Loss: 0.0321 | Val Loss: 4.1896 | Val Acc: 0.2723 | LR: 0.000148\n",
      "Epoch 91/100 | Train Loss: 0.0351 | Val Loss: 4.2635 | Val Acc: 0.2774 | LR: 0.000120\n",
      "Epoch 92/100 | Train Loss: 0.0328 | Val Loss: 4.1826 | Val Acc: 0.2799 | LR: 0.000095\n",
      "Epoch 93/100 | Train Loss: 0.0333 | Val Loss: 4.1620 | Val Acc: 0.2888 | LR: 0.000073\n",
      "Epoch 94/100 | Train Loss: 0.0300 | Val Loss: 4.1603 | Val Acc: 0.2901 | LR: 0.000054\n",
      "Epoch 95/100 | Train Loss: 0.0293 | Val Loss: 4.2129 | Val Acc: 0.2913 | LR: 0.000037\n",
      "Epoch 96/100 | Train Loss: 0.0312 | Val Loss: 4.1875 | Val Acc: 0.2812 | LR: 0.000024\n",
      "Epoch 97/100 | Train Loss: 0.0272 | Val Loss: 4.2033 | Val Acc: 0.2863 | LR: 0.000013\n",
      "Epoch 98/100 | Train Loss: 0.0299 | Val Loss: 4.2228 | Val Acc: 0.2863 | LR: 0.000006\n",
      "Epoch 99/100 | Train Loss: 0.0314 | Val Loss: 4.2365 | Val Acc: 0.2774 | LR: 0.000001\n",
      "Epoch 100/100 | Train Loss: 0.0278 | Val Loss: 4.1945 | Val Acc: 0.2926 | LR: 0.000000\n",
      "\n",
      "Training complete in 72m 55s\n",
      "Best Validation Accuracy: 0.2926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. SUPER-CONVERGENCE TRAINING LOOP\n",
    "# ==========================================\n",
    "import time\n",
    "\n",
    "# 1. SETUP\n",
    "\n",
    "print(\"Initializing ResNet with Dropout & OneCycleLR...\")\n",
    "model = ResNetFromScratch(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# OPTIMIZER: AdamW (Better weight decay handling)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# SCHEDULER: OneCycleLR\n",
    "# This ramps the LR up to 'max_lr' then down to 0. \n",
    "# It is extremely effective for training from scratch.\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, \n",
    "    max_lr=0.003,              # Peak learning rate\n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=len(train_loader)\n",
    ")\n",
    "\n",
    "# 2. TRAINING ENGINE\n",
    "# -----------------------------\n",
    "best_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Starting training on {DEVICE} for {EPOCHS} epochs...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # --- TRAIN PHASE ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # STEP SCHEDULER (OneCycleLR updates every BATCH, not every EPOCH)\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # --- VALIDATION PHASE ---\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels) # Calc val loss too\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    val_acc = correct / total\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    \n",
    "    # Get current LR for printout\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {epoch_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | LR: {current_lr:.6f}\")\n",
    "    \n",
    "    # --- SAVE BEST MODEL ---\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(model.state_dict(), 'best_custom_model.pth')\n",
    "\n",
    "# End of training\n",
    "time_elapsed = time.time() - start_time\n",
    "print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "print(f'Best Validation Accuracy: {best_acc:.4f}')\n",
    "\n",
    "# Load best weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa5581f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T09:45:22.082851Z",
     "iopub.status.busy": "2025-12-14T09:45:22.082326Z",
     "iopub.status.idle": "2025-12-14T09:46:37.677836Z",
     "shell.execute_reply": "2025-12-14T09:46:37.677047Z"
    },
    "papermill": {
     "duration": 75.610401,
     "end_time": "2025-12-14T09:46:37.685518",
     "exception": false,
     "start_time": "2025-12-14T09:45:22.075117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "Saved submission_scratch.csv!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 7. GENERATE SUBMISSION\n",
    "# ==========================================\n",
    "# Load Best Model\n",
    "model.load_state_dict(torch.load('best_custom_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_dataset = BirdDataset(\n",
    "    csv_file=f'{DATA_PATH}/test_images_path.csv',\n",
    "    root_dir=f'{DATA_PATH}',\n",
    "    transform=val_transforms # No augmentation for testing\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "all_ids = []\n",
    "\n",
    "print(\"Generating predictions...\")\n",
    "with torch.no_grad():\n",
    "    for inputs, ids in test_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Convert back to 1-200 range\n",
    "        predicted = predicted.cpu().numpy() + 1 \n",
    "        \n",
    "        all_preds.extend(predicted)\n",
    "        all_ids.extend(ids.numpy())\n",
    "\n",
    "# Save CSV\n",
    "submission = pd.DataFrame({'id': all_ids, 'label': all_preds})\n",
    "submission.to_csv('submission_scratch5.csv', index=False)\n",
    "print(\"Saved submission_scratch.csv!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13909210,
     "sourceId": 116520,
     "sourceType": "competition"
    },
    {
     "datasetId": 9010436,
     "sourceId": 14139279,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4466.631514,
   "end_time": "2025-12-14T09:46:40.138133",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-14T08:32:13.506619",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
