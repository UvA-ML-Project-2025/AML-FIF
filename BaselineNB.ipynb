{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07a2af8a",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "07a2af8a"
      },
      "source": [
        "# AML - 2025 : Feather in Focus - The Baseline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "uKSPK9FxZ-lB"
      },
      "id": "uKSPK9FxZ-lB",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SETUP: Mount Google Drive\n",
        "# ---------------------------------------------------------\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/AML2025\"\n",
        "\n",
        "DATA_PATH = os.path.join(BASE_PATH, \"Dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iweM-veyaIQ7",
        "outputId": "1329afc4-b1a4-4a83-c8a7-1a429a7907f3"
      },
      "id": "iweM-veyaIQ7",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. DEFINE THE DATASET CLASS\n",
        "# ---------------------------------------------------------\n",
        "class BirdDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # FIX: The CSV labels are 1-200, but PyTorch needs 0-199.\n",
        "        # We subtract 1 from every label.\n",
        "        self.data['label'] = self.data['label'] - 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get path from CSV (e.g., \"/train_images/1.jpg\")\n",
        "        img_path = self.data.iloc[idx, 0]\n",
        "\n",
        "        # Remove leading slash if present to join paths correctly\n",
        "        if img_path.startswith(\"/\"):\n",
        "            img_path = img_path[1:]\n",
        "\n",
        "        # Full path: /content/drive/.../train_images/1.jpg\n",
        "        full_path = os.path.join(self.root_dir, img_path)\n",
        "\n",
        "        # Load Image\n",
        "        try:\n",
        "            image = Image.open(full_path).convert(\"RGB\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"MISSING IMAGE: {full_path}\")\n",
        "            # Return a black image if file is missing (prevents crash)\n",
        "            image = Image.new('RGB', (224, 224))\n",
        "\n",
        "        label = self.data.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# 3. CREATE DATA LOADERS\n",
        "# ---------------------------------------------------------\n",
        "# Define standard formatting (Resize to 224x224)\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Initialize Dataset\n",
        "# Note: Pointing to where 'train_images.csv' is located\n",
        "dataset = BirdDataset(\n",
        "    csv_file=f'{DATA_PATH}/train_images.csv',\n",
        "    root_dir=DATA_PATH,\n",
        "    transform=data_transforms\n",
        ")\n",
        "\n",
        "# Split: 80% Train, 20% Validation\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create the Loaders (The final delivery)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\" Data Loaded Successfully!\")\n",
        "print(f\"Training Images: {len(train_dataset)}\")\n",
        "print(f\"Validation Images: {len(val_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R0uRJb16yhX",
        "outputId": "cfdab3c3-ec0d-4c63-d75e-0b32f3fa86d7"
      },
      "id": "2R0uRJb16yhX",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Data Loaded Successfully!\n",
            "Training Images: 3140\n",
            "Validation Images: 786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# defining the baseline model\n",
        "def build_baseline_model(num_classes=200):\n",
        "    # 1. Load the Pre-trained ResNet50\n",
        "    # \"IMAGENET1K_V1\" means it uses the best available pre-trained weights\n",
        "    weights = models.ResNet50_Weights.IMAGENET1K_V1\n",
        "    model = models.resnet50(weights=weights)\n",
        "\n",
        "    # 2. FREEZE the weights\n",
        "    # We turn off gradient calculation for all existing layers\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 3. REPLACE the \"Head\" (The final layer)\n",
        "    # ResNet's output layer is called 'fc' (Fully Connected)\n",
        "    # in_features: 2048 (Standard for ResNet50)\n",
        "    # out_features: 200 (Your specific number of bird classes)\n",
        "    model.fc = nn.Linear(in_features=2048, out_features=num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = build_baseline_model().to(device)\n",
        "\n",
        "print(f\"Model Loaded Successfully on: {device}\")\n",
        "print(f\"Structure: ResNet50 (Frozen) -> Linear Head (200 classes)\")"
      ],
      "metadata": {
        "id": "hU8wQV7x7cMq"
      },
      "id": "hU8wQV7x7cMq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import time\n",
        "import copy\n",
        "\n",
        "# 1. SETUP: Loss Function & Optimizer\n",
        "# ---------------------------------------------------------\n",
        "# CrossEntropy is standard for multi-class classification (Bird 1 vs Bird 2 vs ...)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# We only optimize 'model.fc.parameters()' because the rest is FROZEN\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "# 2. THE TRAINING ENGINE\n",
        "# ---------------------------------------------------------\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # Store history to plot later\n",
        "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # --- TRAINING PHASE ---\n",
        "        model.train()  # Set model to training mode\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward -> Backward -> Optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        print(f'Train Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        # --- VALIDATION PHASE ---\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "        val_loss = 0.0\n",
        "        corrects = 0\n",
        "\n",
        "        with torch.no_grad(): # Don't track gradients during validation\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = corrects.double() / len(val_loader.dataset)\n",
        "\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc.item())\n",
        "\n",
        "        print(f'Val Loss:   {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        # Deep Copy the model if it's the best one so far\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print() # Empty line\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best Val Acc: {best_acc:.4f}')\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n",
        "\n",
        "# 3. EXECUTE TRAINING\n",
        "# ---------------------------------------------------------\n",
        "# We run for 3 epochs just to get a baseline score quickly\n",
        "trained_model, history = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3)\n",
        "\n",
        "# 4. SAVE THE MODEL\n",
        "# ---------------------------------------------------------\n",
        "save_path = f\"{BASE_PATH}/baseline_model.pth\"\n",
        "torch.save(trained_model.state_dict(), save_path)\n",
        "print(f\"Model saved to: {save_path}\")"
      ],
      "metadata": {
        "id": "Bqokbg-L8hZa"
      },
      "id": "Bqokbg-L8hZa",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}